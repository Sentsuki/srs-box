"""
å¤„ç†æœåŠ¡
å®ç°JSONè§„åˆ™é›†åˆå¹¶ã€IPåˆ—è¡¨å¤„ç†ã€è§„åˆ™è¿‡æ»¤åŠŸèƒ½
ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œæ”¯æŒå¤§æ–‡ä»¶å¤„ç†
"""

import json
from pathlib import Path
from typing import Dict, List, Any, Optional, Set, Generator, Tuple

from ..utils.config import ConfigManager
from ..utils.logger import Logger
from ..utils.file_utils import FileUtils
from .downloader import DownloadedData


class ProcessedData:
    """å¤„ç†åçš„æ•°æ®ç»“æœç±»"""
    
    def __init__(self, ruleset_name: str):
        self.ruleset_name = ruleset_name
        self.ruleset_data: Optional[Dict[str, Any]] = None
        self.output_file: Optional[str] = None
        self.rule_count = 0
        self.rule_types: List[str] = []
        self.filtered_count = 0
        self.success = False
        self.error: Optional[str] = None
    
    def set_success(self, ruleset_data: Dict[str, Any], output_file: str, 
                   rule_count: int, rule_types: List[str], filtered_count: int = 0) -> None:
        """è®¾ç½®æˆåŠŸç»“æœ"""
        self.ruleset_data = ruleset_data
        self.output_file = output_file
        self.rule_count = rule_count
        self.rule_types = rule_types
        self.filtered_count = filtered_count
        self.success = True
    
    def set_error(self, error: str) -> None:
        """è®¾ç½®é”™è¯¯ç»“æœ"""
        self.error = error
        self.success = False


class ProcessorService:
    """å¤„ç†æœåŠ¡ç±»"""
    
    def __init__(self, config_manager: ConfigManager, logger: Logger, file_utils: FileUtils):
        """
        åˆå§‹åŒ–å¤„ç†æœåŠ¡
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨
            logger: æ—¥å¿—è®°å½•å™¨
            file_utils: æ–‡ä»¶å·¥å…·
        """
        self.config_manager = config_manager
        self.logger = logger
        self.file_utils = file_utils
        
        # è¿‡æ»¤å…³é”®è¯é…ç½®
        self.filter_keywords = ['ruleset.skk.moe']
    
    def should_filter_rule_value(self, value: str) -> bool:
        """
        æ£€æŸ¥è§„åˆ™å€¼æ˜¯å¦åº”è¯¥è¢«è¿‡æ»¤æ‰
        
        Args:
            value: è§„åˆ™å€¼
            
        Returns:
            æ˜¯å¦åº”è¯¥è¿‡æ»¤
        """
        if not isinstance(value, str):
            return False
        
        value_lower = value.lower()
        return any(keyword in value_lower for keyword in self.filter_keywords)
    
    def filter_rules(self, rules: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], int]:
        """
        è¿‡æ»¤è§„åˆ™åˆ—è¡¨ï¼Œç§»é™¤åŒ…å«ç‰¹å®šå…³é”®å­—çš„è§„åˆ™
        
        Args:
            rules: è§„åˆ™åˆ—è¡¨
            
        Returns:
            (è¿‡æ»¤åçš„è§„åˆ™åˆ—è¡¨, è¢«è¿‡æ»¤çš„è§„åˆ™æ•°é‡)
        """
        filtered_rules = []
        filtered_count = 0
        
        for rule in rules:
            if not isinstance(rule, dict):
                continue
            
            filtered_rule = {}
            
            for rule_type, rule_values in rule.items():
                if not isinstance(rule_values, list):
                    continue
                
                # è¿‡æ»¤è§„åˆ™å€¼
                original_count = len(rule_values)
                filtered_values = [
                    value for value in rule_values 
                    if not self.should_filter_rule_value(value)
                ]
                filtered_count += original_count - len(filtered_values)
                
                # åªæ·»åŠ éç©ºçš„è§„åˆ™
                if filtered_values:
                    filtered_rule[rule_type] = filtered_values
            
            # åªæ·»åŠ éç©ºçš„è§„åˆ™å¯¹è±¡
            if filtered_rule:
                filtered_rules.append(filtered_rule)
        
        return filtered_rules, filtered_count
    
    def merge_json_rulesets(self, json_data_list: List[Dict[str, Any]], 
                           config_version: int) -> Dict[str, Any]:
        """
        æ™ºèƒ½åˆå¹¶å¤šä¸ªJSONè§„åˆ™é›†ï¼Œå°†ç›¸åŒç±»å‹çš„è§„åˆ™åˆå¹¶åœ¨ä¸€èµ·
        
        Args:
            json_data_list: JSONæ•°æ®åˆ—è¡¨
            config_version: é…ç½®ç‰ˆæœ¬å·
            
        Returns:
            åˆå¹¶åçš„è§„åˆ™é›†
        """
        # ç”¨äºå­˜å‚¨åˆå¹¶åçš„è§„åˆ™ï¼ŒæŒ‰è§„åˆ™ç±»å‹åˆ†ç»„
        rule_groups: Dict[str, Set[str]] = {}
        
        for json_data in json_data_list:
            rules = []
            
            # æå–è§„åˆ™åˆ—è¡¨
            if 'rules' in json_data and isinstance(json_data['rules'], list):
                rules = json_data['rules']
            else:
                # å¦‚æœJSONç»“æ„ä¸æ ‡å‡†ï¼Œå°è¯•ç›´æ¥ä½œä¸ºè§„åˆ™å¤„ç†
                rules = [json_data]
            
            # å¤„ç†æ¯ä¸ªè§„åˆ™
            for rule in rules:
                if not isinstance(rule, dict):
                    continue
                
                # éå†è§„åˆ™ä¸­çš„æ¯ä¸ªå­—æ®µ
                for rule_type, rule_values in rule.items():
                    if not isinstance(rule_values, list):
                        continue
                    
                    # å¦‚æœè¿™ä¸ªè§„åˆ™ç±»å‹è¿˜æ²¡æœ‰ï¼Œåˆ›å»ºæ–°çš„é›†åˆ
                    if rule_type not in rule_groups:
                        rule_groups[rule_type] = set()
                    
                    # åˆå¹¶è§„åˆ™å€¼ï¼Œè‡ªåŠ¨å»é‡
                    for value in rule_values:
                        if isinstance(value, str):
                            rule_groups[rule_type].add(value)
        
        # å°†åˆ†ç»„çš„è§„åˆ™è½¬æ¢ä¸ºæœ€ç»ˆæ ¼å¼
        merged_rules = []
        for rule_type, rule_values in rule_groups.items():
            if rule_values:  # åªæ·»åŠ éç©ºçš„è§„åˆ™
                # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åºï¼ˆä¿è¯è¾“å‡ºä¸€è‡´æ€§ï¼‰
                sorted_values = sorted(list(rule_values))
                merged_rules.append({rule_type: sorted_values})
        
        # åˆ›å»ºåˆå¹¶åçš„è§„åˆ™é›†
        merged_ruleset = {
            "version": config_version,
            "rules": merged_rules
        }
        
        return merged_ruleset
    
    def create_ip_ruleset_from_text_files(self, text_files: List[str], 
                                         config_version: int) -> Dict[str, Any]:
        """
        ä»æ–‡æœ¬æ–‡ä»¶åˆ›å»ºIPè§„åˆ™é›†
        
        Args:
            text_files: æ–‡æœ¬æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            config_version: é…ç½®ç‰ˆæœ¬å·
            
        Returns:
            IPè§„åˆ™é›†æ•°æ®
        """
        ip_list = []
        
        # ä½¿ç”¨ç”Ÿæˆå™¨å¤„ç†å¤§æ–‡ä»¶ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨
        def read_ip_lines() -> Generator[str, None, None]:
            for file_path in text_files:
                try:
                    lines = self.file_utils.read_text_file(file_path)
                    for line in lines:
                        cleaned_line = line.strip()
                        if cleaned_line and not cleaned_line.startswith('#'):
                            yield cleaned_line
                except Exception as e:
                    self.logger.warning(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥: {file_path} - {str(e)}")
        
        # æ”¶é›†æ‰€æœ‰IPï¼Œä½¿ç”¨é›†åˆè‡ªåŠ¨å»é‡
        ip_set = set()
        for ip in read_ip_lines():
            ip_set.add(ip)
        
        # è½¬æ¢ä¸ºæ’åºåˆ—è¡¨
        ip_list = sorted(list(ip_set))
        
        # åˆ›å»ºè§„åˆ™é›†
        ruleset = {
            "version": config_version,
            "rules": [
                {
                    "ip_cidr": ip_list
                }
            ]
        }
        
        return ruleset
    
    def process_ruleset(self, ruleset_name: str, downloaded_data: DownloadedData) -> ProcessedData:
        """
        å¤„ç†å•ä¸ªè§„åˆ™é›†çš„ä¸‹è½½æ•°æ®
        
        Args:
            ruleset_name: è§„åˆ™é›†åç§°
            downloaded_data: ä¸‹è½½çš„æ•°æ®
            
        Returns:
            å¤„ç†ç»“æœ
        """
        self.logger.info(f"ğŸ”„ å¼€å§‹å¤„ç†è§„åˆ™é›†: {ruleset_name}")
        
        processed_data = ProcessedData(ruleset_name)
        
        try:
            config_version = self.config_manager.get_version()
            
            # ä¼˜å…ˆå¤„ç†JSONæ•°æ®
            if downloaded_data.has_json_data():
                self.logger.info(f"ğŸ“„ å¤„ç†JSONè§„åˆ™é›†æ•°æ®: {len(downloaded_data.json_data)} ä¸ª")
                
                if len(downloaded_data.json_data) == 1:
                    # åªæœ‰ä¸€ä¸ªJSONæ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨
                    ruleset_data = downloaded_data.json_data[0]
                    self.logger.info("ğŸ“‹ ä½¿ç”¨å•ä¸ªJSONè§„åˆ™é›†")
                else:
                    # å¤šä¸ªJSONæ–‡ä»¶ï¼Œéœ€è¦åˆå¹¶
                    self.logger.info(f"ğŸ”€ åˆå¹¶ {len(downloaded_data.json_data)} ä¸ªJSONè§„åˆ™é›†")
                    ruleset_data = self.merge_json_rulesets(downloaded_data.json_data, config_version)
                
                # è¿‡æ»¤è§„åˆ™
                if 'rules' in ruleset_data and isinstance(ruleset_data['rules'], list):
                    original_rules = ruleset_data['rules']
                    filtered_rules, filtered_count = self.filter_rules(original_rules)
                    ruleset_data['rules'] = filtered_rules
                    
                    if filtered_count > 0:
                        self.logger.info(f"ğŸš« å·²è¿‡æ»¤ {filtered_count} æ¡åŒ…å«è¿‡æ»¤å…³é”®å­—çš„è§„åˆ™")
                else:
                    filtered_count = 0
                
                # ç»Ÿè®¡è§„åˆ™ä¿¡æ¯
                rule_count = 0
                rule_types = []
                
                for rule in ruleset_data.get('rules', []):
                    for rule_type, rule_values in rule.items():
                        if isinstance(rule_values, list):
                            rule_types.append(f"{rule_type}({len(rule_values)})")
                            rule_count += len(rule_values)
                
                self.logger.success(f"âœ… JSONè§„åˆ™é›†å¤„ç†å®Œæˆ")
                self.logger.info(f"ğŸ“Š è§„åˆ™ç»Ÿè®¡: {', '.join(rule_types)}ï¼Œæ€»è®¡ {rule_count} æ¡è§„åˆ™")
                
            elif downloaded_data.has_text_files():
                # å¤„ç†æ–‡æœ¬æ–‡ä»¶ï¼ˆIPåˆ—è¡¨ï¼‰
                self.logger.info(f"ğŸ“„ å¤„ç†æ–‡æœ¬æ–‡ä»¶: {len(downloaded_data.text_files)} ä¸ª")
                
                ruleset_data = self.create_ip_ruleset_from_text_files(
                    downloaded_data.text_files, 
                    config_version
                )
                
                # ç»Ÿè®¡IPæ•°é‡
                rule_count = 0
                rule_types = []
                filtered_count = 0
                
                for rule in ruleset_data.get('rules', []):
                    for rule_type, rule_values in rule.items():
                        if isinstance(rule_values, list):
                            rule_types.append(f"{rule_type}({len(rule_values)})")
                            rule_count += len(rule_values)
                
                self.logger.success(f"âœ… æ–‡æœ¬è§„åˆ™é›†å¤„ç†å®Œæˆ")
                self.logger.info(f"ğŸ“Š è§„åˆ™ç»Ÿè®¡: {', '.join(rule_types)}ï¼Œæ€»è®¡ {rule_count} æ¡è§„åˆ™")
                
            else:
                # æ²¡æœ‰å¯å¤„ç†çš„æ•°æ®
                processed_data.set_error("æ²¡æœ‰å¯å¤„ç†çš„ä¸‹è½½æ•°æ®")
                return processed_data
            
            # ä¿å­˜å¤„ç†åçš„è§„åˆ™é›†
            output_file = f"{ruleset_name}.json"
            self.file_utils.write_json_file(output_file, ruleset_data)
            
            processed_data.set_success(
                ruleset_data, 
                output_file, 
                rule_count, 
                rule_types, 
                filtered_count
            )
            
            self.logger.success(f"âœ… è§„åˆ™é›†å·²ä¿å­˜åˆ°: {output_file}")
            
        except Exception as e:
            error_msg = f"å¤„ç†è§„åˆ™é›†æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}"
            self.logger.error(f"âŒ {error_msg}")
            processed_data.set_error(error_msg)
        
        return processed_data
    
    def process_all_rulesets(self, download_results: Dict[str, DownloadedData]) -> Dict[str, ProcessedData]:
        """
        å¤„ç†æ‰€æœ‰è§„åˆ™é›†
        
        Args:
            download_results: ä¸‹è½½ç»“æœå­—å…¸
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        results = {}
        
        self.logger.header("å¼€å§‹å¤„ç†é˜¶æ®µ")
        
        # åªå¤„ç†æˆåŠŸä¸‹è½½çš„è§„åˆ™é›†
        successful_downloads = {
            name: data for name, data in download_results.items() 
            if data.is_successful()
        }
        
        if not successful_downloads:
            self.logger.warning("âš ï¸ æ²¡æœ‰æˆåŠŸä¸‹è½½çš„è§„åˆ™é›†éœ€è¦å¤„ç†")
            return results
        
        self.logger.info(f"ğŸ“‹ éœ€è¦å¤„ç† {len(successful_downloads)} ä¸ªè§„åˆ™é›†")
        
        for i, (ruleset_name, downloaded_data) in enumerate(successful_downloads.items(), 1):
            self.logger.step(f"å¤„ç†è§„åˆ™é›†: {ruleset_name}", i, len(successful_downloads))
            
            try:
                processed_data = self.process_ruleset(ruleset_name, downloaded_data)
                results[ruleset_name] = processed_data
                
            except Exception as e:
                self.logger.error(f"âŒ è§„åˆ™é›† {ruleset_name} å¤„ç†å¼‚å¸¸: {str(e)}")
                # åˆ›å»ºå¤±è´¥çš„å¤„ç†æ•°æ®
                failed_data = ProcessedData(ruleset_name)
                failed_data.set_error(f"å¤„ç†å¼‚å¸¸: {str(e)}")
                results[ruleset_name] = failed_data
            
            # æ·»åŠ åˆ†éš”çº¿ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
            if i < len(successful_downloads):
                self.logger.info("â”€" * 50)
        
        # è¾“å‡ºæ€»ä½“ç»Ÿè®¡
        successful_processed = sum(1 for data in results.values() if data.success)
        self.logger.separator("å¤„ç†é˜¶æ®µå®Œæˆ")
        self.logger.success(f"âœ… å¤„ç†å®Œæˆ: {successful_processed}/{len(successful_downloads)} ä¸ªè§„åˆ™é›†æˆåŠŸ")
        
        return results
    
    def get_processing_statistics(self, results: Dict[str, ProcessedData]) -> Dict[str, Any]:
        """
        è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            results: å¤„ç†ç»“æœå­—å…¸
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        total_rulesets = len(results)
        successful_rulesets = sum(1 for data in results.values() if data.success)
        total_rules = sum(data.rule_count for data in results.values() if data.success)
        total_filtered = sum(data.filtered_count for data in results.values() if data.success)
        
        # ç»Ÿè®¡è§„åˆ™ç±»å‹
        rule_type_counts = {}
        for data in results.values():
            if data.success:
                for rule_type in data.rule_types:
                    # æå–è§„åˆ™ç±»å‹åç§°ï¼ˆå»æ‰æ•°é‡ï¼‰
                    type_name = rule_type.split('(')[0]
                    if type_name not in rule_type_counts:
                        rule_type_counts[type_name] = 0
                    rule_type_counts[type_name] += 1
        
        return {
            'total_rulesets': total_rulesets,
            'successful_rulesets': successful_rulesets,
            'total_rules': total_rules,
            'total_filtered': total_filtered,
            'rule_type_counts': rule_type_counts,
            'success_rate': (successful_rulesets / total_rulesets * 100) if total_rulesets > 0 else 0
        }