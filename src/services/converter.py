"""
è½¬æ¢æœåŠ¡
å¤„ç†converté…ç½®ä¸­çš„é“¾æ¥ï¼Œä½¿ç”¨åŸæœ‰çš„è½¬æ¢é€»è¾‘ç”ŸæˆJSONè§„åˆ™é›†
èå…¥ç°æœ‰çš„ä¸‹è½½-å¤„ç†-ç¼–è¯‘æ¶æ„
"""

import json
import pandas as pd
import re
import yaml
import ipaddress
from io import StringIO
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple

from ..utils.config import ConfigManager
from ..utils.logger import Logger
from ..utils.file_utils import FileUtils
from ..utils.network import NetworkUtils
from .downloader import DownloadService, DownloadedData


class ConvertedData:
    """è½¬æ¢æ•°æ®ç»“æœç±»"""
    
    def __init__(self, convert_name: str):
        self.convert_name = convert_name
        self.json_files: List[str] = []
        self.srs_files: List[str] = []
        self.success_count = 0
        self.total_count = 0
        self.errors: List[str] = []
    
    def add_converted_file(self, json_file: str, srs_file: str) -> None:
        """æ·»åŠ è½¬æ¢æˆåŠŸçš„æ–‡ä»¶"""
        self.json_files.append(json_file)
        self.srs_files.append(srs_file)
        self.success_count += 1
    
    def add_error(self, error: str) -> None:
        """æ·»åŠ é”™è¯¯ä¿¡æ¯"""
        self.errors.append(error)
    
    def set_total_count(self, count: int) -> None:
        """è®¾ç½®æ€»æ•°é‡"""
        self.total_count = count
    
    def is_successful(self) -> bool:
        """æ˜¯å¦æœ‰æˆåŠŸè½¬æ¢çš„æ•°æ®"""
        return self.success_count > 0


class ConverterService:
    """è½¬æ¢æœåŠ¡ç±»"""
    
    def __init__(self, config_manager: ConfigManager, logger: Logger, 
                 network_utils: NetworkUtils, file_utils: FileUtils):
        """
        åˆå§‹åŒ–è½¬æ¢æœåŠ¡
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨
            logger: æ—¥å¿—è®°å½•å™¨
            network_utils: ç½‘ç»œå·¥å…·
            file_utils: æ–‡ä»¶å·¥å…·
        """
        self.config_manager = config_manager
        self.logger = logger
        self.network_utils = network_utils
        self.file_utils = file_utils
        self.download_service = DownloadService(config_manager, logger, network_utils, file_utils)
        
        # æ˜ å°„å­—å…¸ - ä»åŸæœ‰convert.pyç§»æ¤
        self.MAP_DICT = {
            'DOMAIN-SUFFIX': 'domain_suffix', 'HOST-SUFFIX': 'domain_suffix', 
            'host-suffix': 'domain_suffix', 'DOMAIN': 'domain', 'HOST': 'domain', 
            'host': 'domain', 'DOMAIN-KEYWORD': 'domain_keyword', 
            'HOST-KEYWORD': 'domain_keyword', 'host-keyword': 'domain_keyword', 
            'IP-CIDR': 'ip_cidr', 'ip-cidr': 'ip_cidr', 'IP-CIDR6': 'ip_cidr', 
            'IP6-CIDR': 'ip_cidr', 'SRC-IP-CIDR': 'source_ip_cidr', 
            'GEOIP': 'geoip', 'DST-PORT': 'port', 'SRC-PORT': 'source_port', 
            "URL-REGEX": "domain_regex", "DOMAIN-REGEX": "domain_regex"
        }
    
    def read_yaml_from_url(self, url: str) -> Any:
        """
        ä»URLè¯»å–YAMLæ•°æ®ï¼Œä½¿ç”¨DownloadServiceä¸‹è½½
        
        Args:
            url: YAMLæ–‡ä»¶URL
            
        Returns:
            è§£æåçš„YAMLæ•°æ®
            
        Raises:
            Exception: ä¸‹è½½æˆ–è§£æå¤±è´¥
        """
        temp_dir = Path("temp") / "convert" / "temp_yaml"
        self.file_utils.ensure_dir(temp_dir)
        
        # ä½¿ç”¨DownloadServiceä¸‹è½½æ–‡æœ¬æ–‡ä»¶
        text_files = self.download_service.download_text_rulesets([url], temp_dir)
        
        if not text_files:
            raise Exception(f"æ— æ³•ä¸‹è½½YAMLæ–‡ä»¶: {url}")
        
        # è¯»å–ä¸‹è½½çš„æ–‡ä»¶
        yaml_content = self.file_utils.read_text_file(text_files[0])
        yaml_data = yaml.safe_load('\n'.join(yaml_content))
        return yaml_data
    
    def read_list_from_url(self, url: str) -> Tuple[Optional[pd.DataFrame], List[Dict]]:
        """
        ä»URLè¯»å–åˆ—è¡¨æ•°æ®ï¼Œä½¿ç”¨DownloadServiceä¸‹è½½
        
        Args:
            url: åˆ—è¡¨æ–‡ä»¶URL
            
        Returns:
            (DataFrameæ•°æ®, é€»è¾‘è§„åˆ™åˆ—è¡¨)
            
        Raises:
            Exception: ä¸‹è½½æˆ–è§£æå¤±è´¥
        """
        temp_dir = Path("temp") / "convert" / "temp_list"
        self.file_utils.ensure_dir(temp_dir)
        
        # ä½¿ç”¨DownloadServiceä¸‹è½½æ–‡æœ¬æ–‡ä»¶
        text_files = self.download_service.download_text_rulesets([url], temp_dir)
        
        if not text_files:
            raise Exception(f"æ— æ³•ä¸‹è½½åˆ—è¡¨æ–‡ä»¶: {url}")
        
        # è¯»å–ä¸‹è½½çš„æ–‡ä»¶
        csv_content = self.file_utils.read_text_file(text_files[0])
        csv_data = StringIO('\n'.join(csv_content))
        df = pd.read_csv(csv_data, header=None, 
                        names=['pattern', 'address', 'other', 'other2', 'other3'], 
                        on_bad_lines='skip')
        
        filtered_rows = []
        rules = []
        
        # å¤„ç†é€»è¾‘è§„åˆ™
        if 'AND' in df['pattern'].values:
            and_rows = df[df['pattern'].str.contains('AND', na=False)]
            for _, row in and_rows.iterrows():
                rule = {
                    "type": "logical",
                    "mode": "and",
                    "rules": []
                }
                pattern = ",".join(row.values.astype(str))
                components = re.findall(r'\((.*?)\)', pattern)
                for component in components:
                    for keyword in self.MAP_DICT.keys():
                        if keyword in component:
                            match = re.search(f'{keyword},(.*)', component)
                            if match:
                                value = match.group(1)
                                rule["rules"].append({
                                    self.MAP_DICT[keyword]: value
                                })
                rules.append(rule)
        
        for index, row in df.iterrows():
            if 'AND' not in row['pattern']:
                filtered_rows.append(row)
        
        df_filtered = pd.DataFrame(filtered_rows, columns=['pattern', 'address', 'other', 'other2', 'other3'])
        return df_filtered, rules
    
    def is_ipv4_or_ipv6(self, address: str) -> Optional[str]:
        """
        æ£€æŸ¥åœ°å€æ˜¯å¦ä¸ºIPv4æˆ–IPv6
        
        Args:
            address: è¦æ£€æŸ¥çš„åœ°å€
            
        Returns:
            'ipv4', 'ipv6' æˆ– None
        """
        try:
            ipaddress.IPv4Network(address)
            return 'ipv4'
        except ValueError:
            try:
                ipaddress.IPv6Network(address)
                return 'ipv6'
            except ValueError:
                return None
    
    def parse_and_convert_to_dataframe(self, link: str) -> Tuple[Optional[pd.DataFrame], List[Dict]]:
        """
        è§£æé“¾æ¥å¹¶è½¬æ¢ä¸ºDataFrame
        
        Args:
            link: è¦è§£æçš„é“¾æ¥
            
        Returns:
            (DataFrameæ•°æ®, é€»è¾‘è§„åˆ™åˆ—è¡¨)
        """
        # æ ¹æ®é“¾æ¥æ‰©å±•ååˆ†æƒ…å†µå¤„ç†
        if link.endswith('.yaml') or link.endswith('.txt'):
            yaml_data = self.read_yaml_from_url(link)
            rows = []
            if not isinstance(yaml_data, str):
                items = yaml_data.get('payload', [])
            else:
                items = yaml_data.splitlines()
            
            for item in items:
                if isinstance(item, str):
                    # ç®€å•å¤„ç†ï¼Œå‡è®¾æ¯è¡Œæ˜¯ä¸€ä¸ªpattern:addresså¯¹
                    parts = item.split(',', 1)
                    if len(parts) == 2:
                        rows.append({'pattern': parts[0].strip(), 'address': parts[1].strip()})
                    else:
                        rows.append({'pattern': 'domain', 'address': item.strip()})
                elif isinstance(item, dict):
                    for key, value in item.items():
                        if isinstance(value, list):
                            for v in value:
                                rows.append({'pattern': key, 'address': v})
                        else:
                            rows.append({'pattern': key, 'address': value})
            
            df = pd.DataFrame(rows)
            return df, []  # YAMLé€šå¸¸æ²¡æœ‰é€»è¾‘è§„åˆ™
        else:
            return self.read_list_from_url(link)
    
    def convert_ruleset(self, convert_name: str, urls: List[str]) -> ConvertedData:
        """
        è½¬æ¢å•ä¸ªconvertè§„åˆ™é›†çš„æ‰€æœ‰é“¾æ¥ï¼Œå¹¶åˆå¹¶è§„åˆ™åˆ°ä¸€ä¸ªJSONæ–‡ä»¶
        
        Args:
            convert_name: convertè§„åˆ™é›†åç§°
            urls: URLåˆ—è¡¨
            
        Returns:
            è½¬æ¢æ•°æ®ç»“æœ
        """
        self.logger.info(f"ğŸ”„ å¼€å§‹è½¬æ¢è§„åˆ™é›†: {convert_name}")
        self.logger.info(f"ğŸ“‹ é“¾æ¥æ•°é‡: {len(urls)}")
        
        # åˆ›å»ºè½¬æ¢ç»“æœå¯¹è±¡
        converted_data = ConvertedData(convert_name)
        converted_data.set_total_count(len(urls))
        
        # è·å–è¾“å‡ºç›®å½•é…ç½®ï¼ˆç›´æ¥ä½¿ç”¨json_dirï¼Œæ— å­ç›®å½•ï¼‰
        output_config = self.config_manager.get_output_config()
        json_dir = Path(output_config["json_dir"])
        self.file_utils.ensure_dir(json_dir)
        
        # åˆå§‹åŒ–åˆå¹¶ç»“æ„
        merged_by_type = {}  # pattern -> set of stripped addresses (for dedup)
        all_logic_rules = []  # æ”¶é›†æ‰€æœ‰é€»è¾‘è§„åˆ™
        domain_entries = set()  # å•ç‹¬æ”¶é›†domainï¼Œç”¨äºå»é‡å¹¶æ’å…¥å¼€å¤´
        
        for i, url in enumerate(urls, 1):
            self.logger.info(f"ğŸ”„ è½¬æ¢é“¾æ¥ ({i}/{len(urls)}): {url}")
            
            try:
                # æ ¹æ®é“¾æ¥ç±»å‹è§£æ
                df, logic_rules = self.parse_and_convert_to_dataframe(url)
                
                # æ”¶é›†é€»è¾‘è§„åˆ™
                all_logic_rules.extend(logic_rules)
                
                # è¿‡æ»¤df
                filtered_rows = []
                for index, row in df.iterrows():
                    if 'AND' not in row['pattern']:
                        filtered_rows.append(row)
                df_filtered = pd.DataFrame(filtered_rows, columns=['pattern', 'address', 'other', 'other2', 'other3'])
                
                # groupbyå¹¶åˆå¹¶åˆ°merged_by_type
                for pattern, addresses in df_filtered.groupby('pattern')['address'].apply(list).to_dict().items():
                    stripped = {addr.strip() for addr in addresses}  # set for dedup
                    mapped_pattern = self.MAP_DICT.get(pattern, pattern)  # æ˜ å°„åˆ°æ ‡å‡†ç±»å‹
                    
                    if mapped_pattern == 'domain':
                        domain_entries.update(stripped)
                    else:
                        if mapped_pattern not in merged_by_type:
                            merged_by_type[mapped_pattern] = set()
                        merged_by_type[mapped_pattern].update(stripped)
            
            except Exception as e:
                self.logger.warning(f"âš ï¸ é“¾æ¥è½¬æ¢å¤±è´¥: {url} - {str(e)}")
                converted_data.add_error(f"è½¬æ¢å¤±è´¥: {url} - {str(e)}")
                continue
        
        # å¦‚æœæœ‰æˆåŠŸå¤„ç†çš„é“¾æ¥ï¼Œæ„å»ºåˆå¹¶çš„è§„åˆ™é›†
        if merged_by_type or all_logic_rules or domain_entries:
            merged_ruleset = {"version": self.config_manager.get_version(), "rules": []}
            
            # æ·»åŠ édomainè§„åˆ™
            for pattern, values in merged_by_type.items():
                if values:
                    sorted_values = sorted(list(values))  # å¯é€‰ï¼šæ’åº
                    merged_ruleset["rules"].append({pattern: sorted_values})
            
            # æ·»åŠ domainï¼ˆæ’å…¥å¼€å¤´ï¼Œå»é‡ï¼‰
            if domain_entries:
                sorted_domains = sorted(list(domain_entries))
                merged_ruleset["rules"].insert(0, {'domain': sorted_domains})
            
            # æ·»åŠ é€»è¾‘è§„åˆ™ï¼ˆè¿½åŠ åˆ°æœ«å°¾ï¼‰
            merged_ruleset["rules"].extend(all_logic_rules)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨convert_nameï¼‰
            file_name = json_dir / f"{convert_name}.json"
            
            # å†™å…¥JSONæ–‡ä»¶
            with open(file_name, 'w', encoding='utf-8') as output_file:
                result_rules_str = json.dumps(self.sort_dict(merged_ruleset), ensure_ascii=False, indent=2)
                result_rules_str = result_rules_str.replace('\\\\', '\\')
                output_file.write(result_rules_str)
            
            converted_data.add_converted_file(str(file_name), "")
            self.logger.info(f"âœ… è½¬æ¢å®Œæˆï¼ˆåˆå¹¶åˆ°å•ä¸ªæ–‡ä»¶ï¼‰: {file_name}")
        else:
            self.logger.error(f"âŒ è§„åˆ™é›† {convert_name} æ— æœ‰æ•ˆæ•°æ®")
        
        # è¾“å‡ºè½¬æ¢ç»“æœæ‘˜è¦
        if converted_data.is_successful():
            self.logger.info(f"âœ… è§„åˆ™é›† {convert_name} è½¬æ¢å®Œæˆ")
            self.logger.info(f"ğŸ“Š æˆåŠŸ: {converted_data.success_count}/{converted_data.total_count}")
            self.logger.info(f"ğŸ“„ JSONæ–‡ä»¶: {len(converted_data.json_files)} ä¸ª")
        else:
            self.logger.error(f"âŒ è§„åˆ™é›† {convert_name} è½¬æ¢å¤±è´¥")
        
        # è¾“å‡ºé”™è¯¯ä¿¡æ¯
        for error in converted_data.errors:
            self.logger.warning(f"âš ï¸ {error}")
        
        return converted_data
    
    def convert_all_rulesets(self) -> Dict[str, ConvertedData]:
        """
        è½¬æ¢æ‰€æœ‰converté…ç½®ä¸­çš„è§„åˆ™é›†
        
        Returns:
            convertè§„åˆ™é›†åç§°åˆ°è½¬æ¢æ•°æ®çš„æ˜ å°„
        """
        # è·å–converté…ç½®
        config = self.config_manager.load_config()
        convert_config = config.get('convert', {})
        
        if not convert_config:
            self.logger.info("ğŸ“‹ æ²¡æœ‰å‘ç°converté…ç½®ï¼Œè·³è¿‡è½¬æ¢é˜¶æ®µ")
            return {}
        
        results = {}
        
        self.logger.header("å¼€å§‹è½¬æ¢é˜¶æ®µ")
        self.logger.info(f"ğŸ“‹ å‘ç° {len(convert_config)} ä¸ªconvertè§„åˆ™é›†")
        
        for i, (convert_name, urls) in enumerate(convert_config.items(), 1):
            self.logger.step(f"è½¬æ¢è§„åˆ™é›†: {convert_name}", i, len(convert_config))
            
            try:
                converted_data = self.convert_ruleset(convert_name, urls)
                results[convert_name] = converted_data
                
            except Exception as e:
                self.logger.error(f"âŒ è§„åˆ™é›† {convert_name} è½¬æ¢å¼‚å¸¸: {str(e)}")
                # åˆ›å»ºå¤±è´¥çš„è½¬æ¢æ•°æ®
                failed_data = ConvertedData(convert_name)
                failed_data.set_total_count(len(urls))
                failed_data.add_error(f"è½¬æ¢å¼‚å¸¸: {str(e)}")
                results[convert_name] = failed_data
            
            # æ·»åŠ åˆ†éš”çº¿ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
            if i < len(convert_config):
                self.logger.info("â”€" * 50)
        
        # è¾“å‡ºæ€»ä½“ç»Ÿè®¡
        stats = self.get_convert_statistics(results)
        self.logger.separator("è½¬æ¢é˜¶æ®µå®Œæˆ")
        self.logger.success(f"âœ… è½¬æ¢å®Œæˆ: {stats['successful_urls']}/{stats['total_urls']} ä¸ªé…ç½®æˆåŠŸ")
        
        return results
    
    def get_convert_statistics(self, results: Dict[str, ConvertedData]) -> Dict[str, Any]:
        """
        è·å–è½¬æ¢ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            results: è½¬æ¢ç»“æœå­—å…¸
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        total_converts = len(results)
        successful_converts = sum(1 for data in results.values() if data.is_successful())
        total_urls = sum(data.total_count for data in results.values())
        successful_urls = sum(data.success_count for data in results.values())
        total_json_files = sum(len(data.json_files) for data in results.values())
        
        return {
            'total_converts': total_converts,
            'successful_converts': successful_converts,
            'total_urls': total_urls,
            'successful_urls': successful_urls,
            'total_json_files': total_json_files,
            'success_rate': (successful_urls / total_urls * 100) if total_urls > 0 else 0
        }

    def sort_dict(self, data: Dict) -> Dict:
        """
        é€’å½’æ’åºå­—å…¸ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        
        Args:
            data: è¦æ’åºçš„å­—å…¸æˆ–æ•°æ®
            
        Returns:
            æ’åºåçš„å­—å…¸
        """
        if isinstance(data, dict):
            return {k: self.sort_dict(v) for k, v in sorted(data.items())}
        elif isinstance(data, list):
            return [self.sort_dict(item) if isinstance(item, (dict, list)) else item for item in data]
        else:
            return data